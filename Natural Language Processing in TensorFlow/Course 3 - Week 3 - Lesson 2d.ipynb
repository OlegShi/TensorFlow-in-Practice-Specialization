{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Course 3 - Week 3 - Lesson 2d.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"P-AhVYeBWgQ3","colab_type":"code","colab":{}},"source":["# NOTE: PLEASE MAKE SURE YOU ARE RUNNING THIS IN A PYTHON3 ENVIRONMENT\n","\n","import tensorflow as tf\n","print(tf.__version__)\n","\n","# This is needed for the iterator over the data\n","# But not necessary if you have TF 2.0 installed\n","#!pip install tensorflow==2.0.0-beta0\n","\n","\n","tf.enable_eager_execution()\n","\n","# !pip install -q tensorflow-datasets"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_IoM4VFxWpMR","colab_type":"code","colab":{}},"source":["import tensorflow_datasets as tfds\n","imdb, info = tfds.load(\"imdb_reviews\", with_info=True, as_supervised=True)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wHQ2Ko0zl7M4","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","train_data, test_data = imdb['train'], imdb['test']\n","\n","training_sentences = []\n","training_labels = []\n","\n","testing_sentences = []\n","testing_labels = []\n","\n","# str(s.tonumpy()) is needed in Python3 instead of just s.numpy()\n","for s,l in train_data:\n","  training_sentences.append(str(s.numpy()))\n","  training_labels.append(l.numpy())\n","  \n","for s,l in test_data:\n","  testing_sentences.append(str(s.numpy()))\n","  testing_labels.append(l.numpy())\n","  \n","training_labels_final = np.array(training_labels)\n","testing_labels_final = np.array(testing_labels)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7n15yyMdmoH1","colab_type":"code","colab":{}},"source":["vocab_size = 10000\n","embedding_dim = 16\n","max_length = 120\n","trunc_type='post'\n","oov_tok = \"<OOV>\"\n","\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n","tokenizer.fit_on_texts(training_sentences)\n","word_index = tokenizer.word_index\n","sequences = tokenizer.texts_to_sequences(training_sentences)\n","padded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type)\n","\n","testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n","testing_padded = pad_sequences(testing_sequences,maxlen=max_length)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9axf0uIXVMhO","colab":{}},"source":["reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n","\n","def decode_review(text):\n","    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n","\n","print(decode_review(padded[1]))\n","print(training_sentences[1])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5NEpdhb8AxID","colab_type":"code","colab":{}},"source":["model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n","    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32)),\n","    tf.keras.layers.Dense(6, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n","model.summary()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"V5LLrXC-uNX6","colab_type":"code","colab":{}},"source":["num_epochs = 50\n","history = model.fit(padded, training_labels_final, epochs=num_epochs, validation_data=(testing_padded, testing_labels_final))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nHGYuU4jPYaj","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","\n","\n","def plot_graphs(history, string):\n","  plt.plot(history.history[string])\n","  plt.plot(history.history['val_'+string])\n","  plt.xlabel(\"Epochs\")\n","  plt.ylabel(string)\n","  plt.legend([string, 'val_'+string])\n","  plt.show()\n","\n","plot_graphs(history, 'accuracy')\n","plot_graphs(history, 'loss')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wSualgGPPK0S","colab_type":"code","colab":{}},"source":["# Model Definition with LSTM\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n","    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n","    tf.keras.layers.Dense(6, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n","model.summary()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K_Jc7cY3Qxke","colab_type":"code","colab":{}},"source":["# Model Definition with Conv1D\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n","    tf.keras.layers.Conv1D(128, 5, activation='relu'),\n","    tf.keras.layers.GlobalAveragePooling1D(),\n","    tf.keras.layers.Dense(6, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n","model.summary()\n"],"execution_count":0,"outputs":[]}]}