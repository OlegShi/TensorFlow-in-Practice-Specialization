{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Course 3 - Week 1 - Lesson 3.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"OkaBMeNDwMel","colab_type":"code","colab":{}},"source":["!wget --no-check-certificate \\\n","    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sarcasm.json \\\n","    -O /tmp/sarcasm.json\n","  \n","import json\n","\n","with open(\"/tmp/sarcasm.json\", 'r') as f:\n","    datastore = json.load(f)\n","\n","\n","sentences = [] \n","labels = []\n","urls = []\n","for item in datastore:\n","    sentences.append(item['headline'])\n","    labels.append(item['is_sarcastic'])\n","    urls.append(item['article_link'])\n","\n","\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","tokenizer = Tokenizer(oov_token=\"<OOV>\")\n","tokenizer.fit_on_texts(sentences)\n","\n","word_index = tokenizer.word_index\n","print(len(word_index))\n","print(word_index)\n","sequences = tokenizer.texts_to_sequences(sentences)\n","padded = pad_sequences(sequences, padding='post')\n","print(padded[0])\n","print(padded.shape)"],"execution_count":0,"outputs":[]}]}