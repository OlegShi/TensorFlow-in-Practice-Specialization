{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Course 3 - Week 3 - Lesson 2c.ipynb","version":"0.3.2","provenance":[{"file_id":"1hJrHjN5rpA01RJl6LDPgG1udgsIda4ke","timestamp":1556829841087},{"file_id":"1OOzqEhzmkFQOtmEGwMhiLxB_D2osx4eM","timestamp":1556803950670}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"jGwXGIXvFhXW","colab_type":"code","colab":{}},"source":["import json\n","import tensorflow as tf\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","!wget --no-check-certificate \\\n","    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sarcasm.json \\\n","    -O /tmp/sarcasm.json\n","\n","vocab_size = 1000\n","embedding_dim = 16\n","max_length = 120\n","trunc_type='post'\n","padding_type='post'\n","oov_tok = \"<OOV>\"\n","training_size = 20000\n","\n","\n","with open(\"/tmp/sarcasm.json\", 'r') as f:\n","    datastore = json.load(f)\n","\n","\n","sentences = []\n","labels = []\n","urls = []\n","for item in datastore:\n","    sentences.append(item['headline'])\n","    labels.append(item['is_sarcastic'])\n","\n","training_sentences = sentences[0:training_size]\n","testing_sentences = sentences[training_size:]\n","training_labels = labels[0:training_size]\n","testing_labels = labels[training_size:]\n","\n","tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n","tokenizer.fit_on_texts(training_sentences)\n","\n","word_index = tokenizer.word_index\n","\n","training_sequences = tokenizer.texts_to_sequences(training_sentences)\n","training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n","\n","testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n","testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n","\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n","    tf.keras.layers.Conv1D(128, 5, activation='relu'),\n","    tf.keras.layers.GlobalMaxPooling1D(),\n","    tf.keras.layers.Dense(24, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n","model.summary()\n","\n","num_epochs = 50\n","history = model.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels), verbose=1)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g9DC6dmLF8DC","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","\n","\n","def plot_graphs(history, string):\n","  plt.plot(history.history[string])\n","  plt.plot(history.history['val_'+string])\n","  plt.xlabel(\"Epochs\")\n","  plt.ylabel(string)\n","  plt.legend([string, 'val_'+string])\n","  plt.show()\n","\n","plot_graphs(history, 'acc')\n","plot_graphs(history, 'loss')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ZEZIUppGhdi","colab_type":"code","colab":{}},"source":["model.save(\"test.h5\")"],"execution_count":0,"outputs":[]}]}